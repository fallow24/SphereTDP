%!TEX root = ../main.tex
\section{Introduction}

Today's robots for mobile mapping come in all shapes and sizes.
State of the art for urban environments are laser scanners mounted to cars.
Smaller robotic systems are particularly used when cars no longer have access.
Examples for this are human operated systems such as Zebedee~\cite{Bosse2012-zebedee}, a small Hokuyo 2D scanner on a spring, that is carried through the environment, VILMA~\cite{JPRS2016}, a rolling FARO scanner operating in profiler mode, RADLER~\cite{Borrmann2020-RADLER}, a SICK 2D laser scanner mounted to a unicycle, or a backpack mounted ``personal laser scanning system'' as in~\cite{LauterbackEtAl2015-Backpack} or~\cite{WWWLeicaBackpack}.
Recently more and more autonomous systems gained maturity.
A stunning example is Boston Dynamics' quadruped ``Spot'' that autonomously navigates and maps human environments~\cite{SpotRobot}.
Also, the mobile mapping approaches implemented on the ANYmal platform such as~\cite{Fankhauser2018-ANYmal} were very successful.
Of all these formats, one has not been explored thoroughly in the scientific community: The spherical mobile mapping robot.
Yet this provides some very promising advantages over the other formats.
For one, the locomotion of a spherical robot inherently results in rotation.
That way, a sensor fixed inside the spherical structure will cover the entire environment, given the required locomotion without the need for additional actuators for the sensors.
This requires a solution for the spherical simultaneous localization and mapping (SLAM) problem, given the six degrees of freedom of the robot.
Secondly, a spherical shell that encloses all sensors protects these from possible hazardous environments.  
For example, the shell stops any dust that deteriorates sensors or actuators when settling at sensitive locations.
In contrast to an usual enclosing the shell can separate the sensors entirely from the environment without the need for a number of points-of-connection. 
A strict requirement then is that the shell is very durable.
This is particularly useful for unknown or dangerous environments.
E.g., old buildings that are in danger of collapsing, narrow underground tunnels, construction sites, or mining shafts. 
The spherical format is, in fact, also suited for space applications.
In the DAEDALUS study~\cite{RossiMaurelliUnnithanetal.2021}, such a robot is proposed that is to be lowered into a lunar cave and create a 3D map of the environment. The authors choose this format as the moon regolith is known to damage instruments and other components.
They also present an approach to protect the shell from accumulating dust and dirt.
However, the spherical format also comes with some disadvantages.
Lidar sensors often have a minimum scan distance, resulting in a less dense (or empty) point cloud when the scanner looks on the ground, whereas density is higher when looking in other directions.
The ground itself is likely to be less populated with points, due to weak angles of incidence while mapping it.
Furthermore, relying on IMU based odometry as a localization technique alone yields inaccurate and noisy pose measurements.
Therefore, a robust registration procedure is needed for spherical robots, that is able to cope with vast differences is point cloud density and high noise regarding pose measurements.

This paper proposes to use such a spherical robot for mobile mapping man-made environments.
In such environments, one advantage are architectural shapes following standard conventions arising from tradition or utility. In particular, there are many flat surfaces such as walls, floors, etc. that are sensed.
Exploiting this fact yields more opportunities for registration as point-to-plane correspondences can be used.
The proposed registration method minimizes the distances of each point to its corresponding plane as an objective function.

The next sections introduce you to the state of the art SLAM algorithms for spherical robots and plane based registration.
We then present our approach, which includes global plane extraction, point to plane correspondences, and an optimized gradient descent that minimizes point to plane distances.
Furthermore, we show the results on simulated, as well on real world datasets. 
